# Musthave_mldl_problem_solving Study

- 머신러닝 딥러닝 문제해결 전략 스터디

## 스터디 목적

- 캐글 입문

## 스터디 방식

1. 머신러닝 딥러닝 문제해결 전략 교재로 캐글 프로세스 이해와 노트북 필사
  - 총 651페이지
2. 반복되는 작업 ToolBox 레포에 정리

## 목차

※1∼5장은 캐글에 대한 간략한 소개이므로 따로 다루지 않을 예정

6. 경진대회 자전거 대여 수요 예측 (p.167 ~ p.236)

    - 회귀문제, simple EDA, simple feature engineering, baseline model, LinearRegression, Ridge, Rasso, GridSearchCV, RandomForestRegressor, rmsle

7. 경진대회 범주형 데이터 이진분류 (~p.296)

    - 

- 2022.08.05 ~ 08.06
  - 1장  파이썬 기반의 머신러닝과 생태계 이해 강의 완강, 교재 읽기, 코드 리뷰
    - Numpy, Pandas
  - 머신러닝 기본과 Numpy, Pandas 관련 내용이므로 굳이 할 필요는 없었지만 팁이 될만한 부분을 건질 수 있을 것을 기대하고 빠른 속도로 공부함
  - 데이터 분석시 헷갈릴 만한 것들 교재에 표시해둠
  
- 2019.11.09 ~ 11.10
  - 2장  사이킷런으로 시작하는 머신러닝 강의 완강, 교재 읽기, 코드 리뷰
    - Sklearn 프레임워크, Model selection (K-fold, Stratified K-fold, cross_val_score, GridSearchCV), 데이터 전처리
  - Model Selection에 집중하여 복습함
  
- 2019.11.11 ~ 11.12

  - 3장  평가 강의 완강, 교재 읽기, 코드 리뷰

    - Accuracy, Confusion Matrix, Precison and Recall, F1 Score, ROC/AUC


- 2019.11.13 ~ 11.16

  - 4장  분류 강의 완강, 교재 읽기, 코드 리뷰

    - Decision Tree, Ensemble(voting, bagging, boosting), GBM, XGBoost, LightBoost, Over/Under Sampling(SMOTE), Stacking
  - 모델 학습 코드에 집중하여 복습함
- 2019.11.17 ~ 11.21

  - 5장  회귀 강의 완강, 교재 읽기, 코드 리뷰
  
    - Gradient Descent, Stochastic Gradient Descent, Linear Regression, Polynomial Regression, Regularized Linear Models (Ridge, Lasso, ElasticNet), Logistic Regression, Tree Regression, Preprocessing(Scaling, Log Transformation, Feature Encoding), Mixed Model Prediction
  - 각 휘귀 모델 별 차이점 숙지
  - 스케일링, 인코딩, 아웃라이어 제거, 하이퍼 파라미터 튜닝에 따라 예측 성능이 향상되는 흐름 복습
- 2019.11.22 ~ 11.24
  - 6장  차원 축소
    - 차원 축소 (피쳐 선택, 피쳐 추출), PCA(Principal Component Analysis), LDA(Linear Discriminant Analysis), SVD(Singular Value Decomposition), Truncated SVD, NMF(Non-Negative Matrix Fatorization)
  - 각 차원 축소 기법 별 선형 대수적 의미를 최대한 이해하며 학습
- 2019.11.25 ~ 11.28
  - 7장  군집화
    - K-means, Cluster Evaluation(실루엣 계수), Mean Shift, GMM, DBSCAN
